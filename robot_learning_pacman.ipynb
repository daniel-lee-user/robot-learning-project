{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ygx8_uItMrjj",
    "outputId": "a34af19b-2d8a-492f-b814-6369347d6d5d"
   },
   "outputs": [],
   "source": [
    "# Set Up:\n",
    "import sys\n",
    "USING_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if USING_COLAB:\n",
    "    !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "    !pip install -U renderlab\n",
    "    !pip install -U colabgymrender\n",
    "    !pip install -U moviepy==0.2.3.5\n",
    "    !pip install imageio==2.4.1\n",
    "    !pip install --upgrade AutoROM\n",
    "    !AutoROM --accept-license\n",
    "    !pip install stable_baselines3  \n",
    "    !pip install \"gymnasium[atari, accept-rom-licesnse]\"\n",
    "\n",
    "import numpy as np\n",
    "import ale_py\n",
    "import shimmy\n",
    "import gymnasium as gym\n",
    "import renderlab as rl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from colabgymrender.recorder import Recorder\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "seed = 24\n",
    "data_seed = 700\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.vec_env.base_vec_env import VecEnv\n",
    "from stable_baselines3.common.env_checker import check_env # for regular envs\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "# not using make_atari_env bc that wraps it in an atari wrapper only for v4 stuff (needs verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ls5ZHspwE66",
    "outputId": "af1ead2f-95f6-4bcd-a417-9e33980c57b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym: 0.29.1\n",
      "ale_py: 0.8.1\n",
      "GPU is available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('gym:', gym.__version__)\n",
    "print('ale_py:', ale_py.__version__)\n",
    "print(\"GPU is available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions from A5 starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fU8oLOuXMw4O"
   },
   "outputs": [],
   "source": [
    "  # Setting the seed to ensure reproducability\n",
    "def reseed(seed, env=None):\n",
    "    '''\n",
    "        Sets the seed for reproducibility\n",
    "\n",
    "        When @param env is provided, also sets the\n",
    "        random number generataor of the gym environment\n",
    "        to this particular seed\n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if env is not None:\n",
    "        env.unwrapped._np_random = gym.utils.seeding.np_random(seed)[0]\n",
    "\n",
    "reseed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cegQssH6M164"
   },
   "outputs": [],
   "source": [
    "def visualize(env_name='ALE/Pacman-v5', algorithm=None, video_name=\"test\", env_args={}):\n",
    "    \"\"\"Visualize a policy network for a given algorithm on a single episode\n",
    "\n",
    "        Args:\n",
    "            env_name: Name of the gym environment to roll out `algorithm` in, it will be instantiated using gym.make or make_vec_env\n",
    "            algorithm (PPOActor): Actor whose policy network will be rolled out for the episode. If\n",
    "            no algorithm is passed in, a random policy will be visualized.\n",
    "            video_name (str): Name for the mp4 file of the episode that will be saved (omit .mp4). Only used\n",
    "            when running on local machine.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_action(obs):\n",
    "        if not algorithm:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            return algorithm.predict(obs)[0]\n",
    "\n",
    "    if USING_COLAB:\n",
    "        from renderlab import RenderFrame\n",
    "        # visualization probably wont work on colab with my new changes\n",
    "\n",
    "        directory = './video'\n",
    "        env_args['render_mode'] = 'rgb_array'\n",
    "        env = gym.make(env_name, **env_args)\n",
    "        env = RenderFrame(env, directory)\n",
    "        obs, info = env.reset()\n",
    "\n",
    "        while True:\n",
    "            action = get_action(obs)\n",
    "            obs, reward, done, truncate, info = env.step(action)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        env.play()\n",
    "    else:\n",
    "        import cv2\n",
    "        # need to specify dimensions correctly (use the print statement)\n",
    "        video = cv2.VideoWriter(f\"videos/{video_name}.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 24, (160,250))\n",
    "\n",
    "        env_args['render_mode'] = 'rgb_array'\n",
    "        #env = gym.make(env_name, **env_args)\n",
    "        #env = gym.wrappers.AtariPreprocessing(env)\n",
    "        env = make_atari_env(env_name, n_envs=1, env_kwargs=env_args)\n",
    "        env = VecFrameStack(env, n_stack=4)\n",
    "        #env.metadata['render_fps'] = 60\n",
    "        obs = env.reset()\n",
    "        #img = plt.imshow(env.render()) # only call this once\n",
    "        while True:\n",
    "            #img.set_data(env.render()) # just update the data\n",
    "            #display.display(plt.gcf())\n",
    "            #display.clear_output(wait=True)\n",
    "            action = get_action(obs)\n",
    "            if(not algorithm):    \n",
    "                action = [action]\n",
    "            obs, reward, done, info  = env.step(action)\n",
    "            if done:\n",
    "                print(reward)\n",
    "                break\n",
    "            im = env.render()\n",
    "            im = im[:,:,::-1]\n",
    "            #print(im.shape)\n",
    "\n",
    "            video.write(im)\n",
    "\n",
    "        video.release()\n",
    "        env.close()\n",
    "        print(f\"Video saved as {video_name}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K-wZhw02M6up"
   },
   "outputs": [],
   "source": [
    "def evaluate_policy(actor, environment, num_episodes=100, progress=True):\n",
    "    '''\n",
    "        Returns the mean trajectory reward of rolling out `actor` on `environment\n",
    "\n",
    "        Parameters\n",
    "        - actor: PPOActor instance, defined in Part 1\n",
    "        - environment: classstable_baselines3.common.vec_env.VecEnv instance\n",
    "        - num_episodes: total number of trajectories to collect and average over\n",
    "    '''\n",
    "    total_rew = 0\n",
    "\n",
    "    iterate = (trange(num_episodes) if progress else range(num_episodes))\n",
    "    for _ in iterate:\n",
    "        obs = environment.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = actor.predict(obs)[0]\n",
    "\n",
    "            next_obs, reward, done, info = environment.step(action)\n",
    "            total_rew += reward\n",
    "\n",
    "            obs = next_obs\n",
    "\n",
    "    return (total_rew / num_episodes).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "q1jQdkNYM8E0",
    "outputId": "4b55f34b-86d3-4d3a-ed85-79da2cd70601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "Video saved as pacman-test.mp4\n"
     ]
    }
   ],
   "source": [
    "# for testing if visualization works (random actions selected)\n",
    "# env arguments are space invader specific\n",
    "# see https://ale.farama.org/environments/#2 for description of params\n",
    "# we use frameskip for training but for visualization we don't use frameskip so we can see what's happening clearly\n",
    "# for dqn we evaluate on same environment as testing\n",
    "env_id = \"ALE/Pacman-v5\"\n",
    "env_args = {\n",
    "    'mode':0,\n",
    "    'difficulty':0,\n",
    "    'obs_type':\"rgb\",\n",
    "    'full_action_space':False,\n",
    "    'frameskip':1\n",
    "    }\n",
    "visualize(env_id, env_args=env_args, video_name=\"pacman-test\")\n",
    "# reward is 0 because randomly picking actions gives you no right answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4bhTk8Tz5G0"
   },
   "source": [
    "# Initialization\n",
    "from A5 starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYoyYveAF0_z",
    "outputId": "ebad88b4-49fb-4fb1-bea4-6bd3cf7ea202"
   },
   "outputs": [],
   "source": [
    "# just one environment for evaluation\n",
    "env1 = make_atari_env(env_id, n_envs=1, env_kwargs=env_args)\n",
    "env1 = VecFrameStack(env1, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "haRabITKFyOe"
   },
   "outputs": [],
   "source": [
    "# 8 environments\n",
    "num_envs = 8\n",
    "env8 = make_atari_env(env_id, n_envs=num_envs, env_kwargs=env_args)\n",
    "env8 = VecFrameStack(env8, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sPyGrbSDc48X"
   },
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env=env1,\n",
    "    callback_on_new_best=None,\n",
    "    callback_after_eval=None,\n",
    "    n_eval_episodes=20,\n",
    "    eval_freq=max(200_000 // num_envs, 1),\n",
    "    log_path='./logs/eval_logs_pacman/',\n",
    "    best_model_save_path='./models/best_ppo_model_pacman/',\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    "    verbose=1,\n",
    "    warn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3-oravlLYA7W"
   },
   "outputs": [],
   "source": [
    "ppomodel = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    env8,\n",
    "    learning_rate=2.5e-4,\n",
    "    n_steps=128,\n",
    "    batch_size=256,\n",
    "    n_epochs=4,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.98,\n",
    "    clip_range=0.1,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training PPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33,
     "referenced_widgets": [
      "0e210792682b4fb0826cc136044ac8cb",
      "6c881044d935465ab71a11a999952f5c"
     ]
    },
    "id": "fqVCgW8zz77F",
    "outputId": "2e6fdfde-4aff-43ac-dc09-1a67fcdef603"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75247025a8e434e9afe7c991ee1d484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2475.60 +/- 667.82\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2475.60 +/- 667.82\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2210.30 +/- 598.39\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2210.30 +/- 598.39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2814.70 +/- 591.86\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2814.70 +/- 591.86\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=800000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=800000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 3024.90 +/- 578.45\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 3024.90 +/- 578.45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2526.60 +/- 555.52\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2526.60 +/- 555.52\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1200000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=1200000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2185.60 +/- 431.15\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2185.60 +/- 431.15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1400000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=1400000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2476.40 +/- 492.24\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2476.40 +/- 492.24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=1600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2634.30 +/- 604.66\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2634.30 +/- 604.66\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=1800000, episode_reward=0.10 +/- 0.30\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=1800000, episode_reward=0.10 +/- 0.30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2622.70 +/- 687.25\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2622.70 +/- 687.25\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=2000000, episode_reward=0.10 +/- 0.30\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=2000000, episode_reward=0.10 +/- 0.30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2762.60 +/- 811.10\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2762.60 +/- 811.10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=2200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=2200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2408.20 +/- 571.26\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2408.20 +/- 571.26\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=2400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=2400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2369.40 +/- 479.97\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2369.40 +/- 479.97\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=2600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=2600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2223.40 +/- 543.07\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2223.40 +/- 543.07\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=2800000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=2800000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2466.20 +/- 515.13\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2466.20 +/- 515.13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=3000000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=3000000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2752.60 +/- 600.29\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2752.60 +/- 600.29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=3200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=3200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2520.30 +/- 486.48\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2520.30 +/- 486.48\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=3400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=3400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2454.40 +/- 399.50\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2454.40 +/- 399.50\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=3600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=3600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2411.70 +/- 503.59\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2411.70 +/- 503.59\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=3800000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=3800000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2511.30 +/- 440.06\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2511.30 +/- 440.06\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=4000000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=4000000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2389.90 +/- 575.45\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2389.90 +/- 575.45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=4200000, episode_reward=0.15 +/- 0.36\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=4200000, episode_reward=0.15 +/- 0.36\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2617.10 +/- 653.62\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2617.10 +/- 653.62\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=4400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=4400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2394.00 +/- 511.54\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2394.00 +/- 511.54\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=4600000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=4600000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2676.20 +/- 648.42\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2676.20 +/- 648.42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=4800000, episode_reward=0.10 +/- 0.30\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=4800000, episode_reward=0.10 +/- 0.30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2608.00 +/- 586.10\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2608.00 +/- 586.10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=5000000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=5000000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2273.60 +/- 512.03\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2273.60 +/- 512.03\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=5200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=5200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2328.40 +/- 606.61\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2328.40 +/- 606.61\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=5400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=5400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2186.20 +/- 637.11\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2186.20 +/- 637.11\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=5600000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=5600000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2670.60 +/- 563.17\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2670.60 +/- 563.17\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=5800000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=5800000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2560.60 +/- 399.39\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2560.60 +/- 399.39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=6000000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=6000000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2499.00 +/- 491.47\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2499.00 +/- 491.47\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=6200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=6200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2527.20 +/- 400.53\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2527.20 +/- 400.53\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=6400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=6400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2525.00 +/- 427.42\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2525.00 +/- 427.42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=6600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=6600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2440.10 +/- 486.50\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2440.10 +/- 486.50\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=6800000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=6800000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2508.00 +/- 500.95\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2508.00 +/- 500.95\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=7000000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=7000000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2536.00 +/- 563.39\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2536.00 +/- 563.39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=7200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=7200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2586.80 +/- 522.23\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2586.80 +/- 522.23\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=7400000, episode_reward=0.10 +/- 0.30\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=7400000, episode_reward=0.10 +/- 0.30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2819.80 +/- 377.01\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2819.80 +/- 377.01\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=7600000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=7600000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2620.00 +/- 595.98\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2620.00 +/- 595.98\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=7800000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=7800000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2507.10 +/- 596.53\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2507.10 +/- 596.53\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=8000000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=8000000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2156.60 +/- 550.96\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2156.60 +/- 550.96\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=8200000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=8200000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2494.80 +/- 538.91\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2494.80 +/- 538.91\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=8400000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=8400000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2270.10 +/- 622.10\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2270.10 +/- 622.10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=8600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=8600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2200.60 +/- 378.23\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2200.60 +/- 378.23\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=8800000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=8800000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2410.60 +/- 563.91\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2410.60 +/- 563.91\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=9000000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=9000000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2149.00 +/- 528.65\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2149.00 +/- 528.65\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=9200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=9200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2379.10 +/- 538.31\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2379.10 +/- 538.31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=9400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=9400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2409.30 +/- 487.15\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2409.30 +/- 487.15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=9600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=9600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2343.30 +/- 549.31\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2343.30 +/- 549.31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=9800000, episode_reward=0.05 +/- 0.22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=9800000, episode_reward=0.05 +/- 0.22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2656.50 +/- 716.73\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2656.50 +/- 716.73\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=10000000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=10000000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 2480.90 +/- 366.33\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 2480.90 +/- 366.33\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1d9a72897e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reseed(seed)\n",
    "# If you get the error that Only one live display may be active at once, either restart colab or set progress bar = False\n",
    "total_timesteps = 10_000_000\n",
    "ppomodel.learn(total_timesteps=total_timesteps, callback=eval_callback, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQbW-DNK0B4n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [02:10<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019999999552965164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_ppo_model = PPO.load(\"models/best_ppo_model_pacman/best_model.zip\", env=env1)\n",
    "\n",
    "print(evaluate_policy(best_ppo_model, env1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8Ryu7hr2iFi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "Video saved as best_ppo_tetris_video.mp4\n"
     ]
    }
   ],
   "source": [
    "visualize('ALE/Pacman-v5', algorithm=best_ppo_model, video_name='best_ppo_pacman_video', env_args=env_args)\n",
    "\n",
    "# might need to rerun with best_ppo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-vpZPdk2jnW"
   },
   "outputs": [],
   "source": [
    "ppomodel.save(\"models/pacman_ppo_10m\")\n",
    "\n",
    "# best model_1 and best_model_2 are using difficulty 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs to train on a different env with different params due to dqn buffer memory size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xOVXB0jGM2B"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "# can only use env1 instead of env8 for training due to memory constraints\n",
    "\n",
    "dqnmodel = DQN(\n",
    "    \"MlpPolicy\",  # Using CNN policy for visual inputs\n",
    "    env1,\n",
    "    learning_rate=1e-4,\n",
    "    buffer_size=100_000,            # Smaller replay buffer\n",
    "    learning_starts=50_000,        # Start learning earlier\n",
    "    batch_size=32,\n",
    "    train_freq=4,                  # Train more frequently\n",
    "    target_update_interval=1000,  # Update target network more frequently\n",
    "    exploration_fraction=0.1,     # Faster exploration decay\n",
    "    exploration_final_eps=0.01,\n",
    "    gamma=0.99,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback_dqn = EvalCallback(\n",
    "    eval_env=env1,\n",
    "    callback_on_new_best=None,\n",
    "    callback_after_eval=None,\n",
    "    n_eval_episodes=10,\n",
    "    eval_freq=200_000,\n",
    "    log_path='./logs/pacman_dqn/',\n",
    "    best_model_save_path='./models/pacman_dqn/',\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    "    verbose=1,\n",
    "    warn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d133b7c06eef45b198ea33054a9750ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1936.40 +/- 4.80\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1936.40 +/- 4.80\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "New best mean reward!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1690.00 +/- 72.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1690.00 +/- 72.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 1922.00 +/- 96.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Episode length: 1922.00 +/- 96.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# If you get the error that Only one live display may be active at once, either restart colab or set progress bar = False\u001b[39;00m\n\u001b[0;32m      4\u001b[0m total_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10_000_000\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdqnmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:560\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    563\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py:97\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m---> 97\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py:38\u001b[0m, in \u001b[0;36mVecFrameStack.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[0;32m     37\u001b[0m ]:\n\u001b[1;32m---> 38\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     observations, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacked_obs\u001b[38;5;241m.\u001b[39mupdate(observations, dones, infos)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observations, rewards, dones, infos\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:70\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m---> 70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\gymnasium\\core.py:467\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\gymnasium\\core.py:467\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\gymnasium\\core.py:515\u001b[0m, in \u001b[0;36mObservationWrapper.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`reset`, returning a modified observation using :meth:`self.observation`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(obs), info\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py:88\u001b[0m, in \u001b[0;36mFireResetEnv.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AtariResetReturn:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     89\u001b[0m     obs, _, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py:135\u001b[0m, in \u001b[0;36mEpisodicLifeEnv.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03mCalls the Gym environment reset, only when lives are exhausted.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03mThis way all states are still reachable even though lives are episodic,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m:return: the first observation of the environment\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwas_real_done:\n\u001b[1;32m--> 135\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# no-op step to advance from terminal/lost life state\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     obs, _, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\gymnasium\\core.py:467\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py:69\u001b[0m, in \u001b[0;36mNoopResetEnv.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m info: Dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(noops):\n\u001b[1;32m---> 69\u001b[0m     obs, _, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoop_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[0;32m     71\u001b[0m         obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\rl\\lib\\site-packages\\shimmy\\atari_env.py:294\u001b[0m, in \u001b[0;36mAtariEnv.step\u001b[1;34m(self, action_ind)\u001b[0m\n\u001b[0;32m    292\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frameskip):\n\u001b[1;32m--> 294\u001b[0m     reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mact(action)\n\u001b[0;32m    295\u001b[0m is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_over(with_truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    296\u001b[0m is_truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_truncated()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reseed(seed)\n",
    "\n",
    "# If you get the error that Only one live display may be active at once, either restart colab or set progress bar = False\n",
    "total_timesteps = 10_000_000\n",
    "dqnmodel.learn(total_timesteps=total_timesteps, callback=eval_callback_dqn, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_dqn_model = DQN.load(\"models/pacman_dqn/best_model.zip\", env=env1)\n",
    "print(evaluate_policy(best_dqn_model, env1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize('ALE/Pacman-v5', algorithm=best_dqn_model, video_name='dqn_pacman', env_args=env_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e210792682b4fb0826cc136044ac8cb": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_6c881044d935465ab71a11a999952f5c",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">  29%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\"></span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">433,664/1,500,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">6:19:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">8:44:36</span> , <span style=\"color: #800000; text-decoration-color: #800000\">34 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[35m  29%\u001b[0m \u001b[38;2;249;38;114m\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[32m433,664/1,500,000 \u001b[0m [ \u001b[33m6:19:00\u001b[0m < \u001b[36m8:44:36\u001b[0m , \u001b[31m34 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "6c881044d935465ab71a11a999952f5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
